{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "221b9c607311486d27f8f2dca7bfa7b0",
     "grade": false,
     "grade_id": "cell-69c370545444c35d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## CS-E4820 Machine Learning: Advanced Probabilistic Methods (spring 2020)\n",
    "Pekka Marttinen, Santosh Hiremath, Marko Järvenpää, Tianyu Cui, Yogesh Kumar, Diego Mesquita, Zheyang Shen, Alexander Aushev, Khaoula El Mekkaoui, Joakim Järvinen.\n",
    "\n",
    "## Assignment 3, due on Tuesday, 4th February at 23:55\n",
    "\n",
    "### Contents\n",
    "1. [Problem 1: Poisson-Gamma](#Problem-1:-Poisson-Gamma)\n",
    "2. [Problem 2: Multivariate Gaussian](#Problem-2:-Multivariate-Gaussian)\n",
    "3. [Problem 3: Posterior of regression weights](#Problem-3:-Posterior-of-regression-weights)\n",
    "\n",
    "\n",
    "\n",
    "## Problem 1: Poisson-Gamma\n",
    "\n",
    "Suppose you have $N$ i.i.d. observations $\\mathbf{x}= \\{x_i\\}_{i=1}^N$ from a $\\operatorname{Poisson}(\\lambda)$ distribution with a rate parameter $\\lambda$ that has a conjugate prior \n",
    "\n",
    "$$\\lambda \\sim \\operatorname{Gamma}(a,b)$$\n",
    "\n",
    "with the shape and rate hyperparameters $a$ and $b$. Derive the posterior distribution $\\lambda|\\bf{x}$.\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```!(imagename_in_the_folder.jpg)```. Latex in here works similarly as you would write it normally! You can use some of the definitions from the exercise description as a reference. The list of valid Latex commands in Jypyter notebook can be found here: http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02cf4daf2d25ad010b90817586dca681",
     "grade": true,
     "grade_id": "cell-f7dadcb39eba615e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$posterior \\;\\; p(\\lambda | x)$$\n",
    "\n",
    "$$ = \\frac{p(x | \\lambda) p(\\lambda)}{p(x)} \\propto p(x | \\lambda)p(\\lambda)$$\n",
    "\n",
    "\n",
    "$$where \\;\\; poisson \\;\\; likelihood \\;\\; L(\\lambda | x)$$\n",
    "\n",
    "$$ = \\prod_{i=}^{N}\\frac{e^{-\\lambda}\\lambda^{x_{i}}}{x_{i}!}$$\n",
    "\n",
    "$$and \\;\\; where \\;\\; conjugate \\;\\; gamma \\;\\; prior \\;\\; p(\\lambda)$$\n",
    "\n",
    "$$ = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\lambda^{\\alpha-1} e^{\\beta\\lambda}$$\n",
    "\n",
    "$$thus \\;\\; we \\;\\; can \\;\\; derive \\;\\;posterior \\;\\; as$$\n",
    "\n",
    "$$ = \\prod_{i=}^{N}\\frac{e^{-\\lambda}\\lambda^{x_{i}}}{x_{i}!} \\times \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\lambda^{\\alpha-1}e^{\\beta\\lambda}$$\n",
    "\n",
    "$$ \\propto e^{-N\\lambda}\\lambda^{\\sum_{i=1}^{N}} x_{i}\\lambda^{\\alpha-1}e^{\\beta\\lambda}$$\n",
    "\n",
    "$$ \\propto e^{-\\lambda(N+b)}\\lambda^{\\alpha+\\sum_{i=1}^{N}x_{i}-1}$$\n",
    "\n",
    "$$ therefore \\;\\; posterior \\;\\; is \\;\\;$$\n",
    "\n",
    "$$\\propto \\lambda | x_{1}, x_{2} ... x_{n} \\sim \\gamma(\\alpha + \\sum_{i=1}^{N}x_{i}, b + N)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "975f99e88e87b0e6d917a280be165237",
     "grade": false,
     "grade_id": "cell-542e75e609ebde4c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 2: Multivariate Gaussian\n",
    "\n",
    "Suppose we have $N$ i.i.d. observations $\\mathbf{X} = \\{\\mathbf{x}_i\\}_{i=1}^N$ from a multivariate Gaussian distribution $$\\mathbf{x}_i \\mid \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$$ with unknown mean parameter $\\boldsymbol{\\mu}$  and a known covariance matrix $\\boldsymbol{\\Sigma}$. As prior information on the mean parameter we have $$ \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\mathbf{m_0}, \\mathbf{S_0}). $$\n",
    "\n",
    "__(a)__ Derive the posterior distribution $p(\\boldsymbol{\\mu}|\\mathbf{X})$ of the mean parameter $\\boldsymbol{\\mu}$. Write your solution in LateX or attach a picture of the solution in the cell below.\n",
    "\n",
    "__(b)__ Compare the Bayesian estimate (posterior mean) to the maximum likelihood estimate by generating $N=10$ observations from the bivariate Gaussian \n",
    "        $$\\mathcal{N}\\left(\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}, \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\right).$$\n",
    "For this you can use the Python function [numpy.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html), making use of the fact that the elements of the bivariate random vectors are independent. In the Bayesian case, use the prior with $\\mathbf{m_0} = [0,0]^T$ and $\\mathbf{S_0} = [\\begin{smallmatrix}0.1 & 0 \\\\ 0 & 0.1\\end{smallmatrix}]$. Report both estimates. Is the Bayesian estimate closer to the true value $\\boldsymbol{\\mu} = [0,0]^T$? Use the code template given below (after the answer cell) to complete your answer.\n",
    "\n",
    "Write your solutions to __(a)__ and __(b)__ in LateX or attach a picture in the answer cell provided below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d30074cf97b73e049a01ca5eca9fe2ac",
     "grade": true,
     "grade_id": "cell-4bda4b8a96febf7b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "**(a)**\n",
    "\n",
    "$$posterior \\;\\; p(\\mu | X)$$\n",
    "\n",
    "$$ = \\frac{p(X | \\mu) p(\\mu)}{p(X)} \\propto p(X | \\mu)p(\\mu)$$\n",
    "\n",
    "$$The\\;\\;density\\;\\;of\\;\\;the\\;\\;D-variate\\;\\;multivariate\\;\\;normal\\;\\;distribution\\;\\;is\\;\\;defined\\;\\;as:$$\n",
    "\n",
    "$$(2\\pi)^{-\\frac{D}{2}}|\\textstyle\\sum|^{-\\frac{1}{2}}e^{-\\frac{1}{2}(x-\\mu)^{T}\\sum^{-1}(x-\\mu)}$$\n",
    "\n",
    "$$Therefore\\;\\;we\\;\\,can\\;\\;write\\;\\;likelihood\\;\\;times\\;\\;prior\\;\\;as:$$\n",
    "\n",
    "$$\\prod_{i=1}^{N}(2\\pi)^{-\\frac{D}{2}}|\\textstyle\\sum|^{-\\frac{1}{2}}e^{-\\frac{1}{2}(x-\\mu)^{T}\\sum^{-1}(x-\\mu))} \\times (2\\pi)^{-\\frac{D}{2}}|S_{0}|^{-\\frac{1}{2}}e^{-\\frac{1}{2}(\\mu-m_{0})^{T}S_{0}^{-1}(\\mu-m_{0})}$$\n",
    "\n",
    "$$where\\;\\;likelihood:$$\n",
    "$$p(X | \\mu) \\propto e^{-\\frac{1}{2}\\sum_{i=1}^{N}(x_{i}-\\mu)^{T}\\sum^{-1}(x_{i}-\\mu})$$\n",
    "\n",
    "$$and\\;\\;where\\;\\;prior:$$\n",
    "\n",
    "$$p(\\mu) \\propto e^{-\\frac{1}{2}(\\mu-m_{0}^{T}S_{0}^{-1}(\\mu-m_{0})}$$\n",
    "\n",
    "$$concatenating\\;\\;the\\;\\;terms,\\;\\;opening\\;\\;the\\;\\;exponents\\;\\;and\\;\\;rewriting\\;\\;the\\;\\,terms:$$\n",
    "\n",
    "$$ln\\;p(\\mu|X) \\propto -\\frac{1}{2}\\textstyle\\sum_{i=1}^{N}(x_{i}-\\mu)^{T}\\textstyle\\sum^{-1}(x_{i}-\\mu) \\times -\\frac{1}{2}(\\mu-m_{0}^{T}S_{0}^{-1}(\\mu-m_{0}))$$\n",
    "\n",
    "$$\\propto -\\frac{1}{2}N\\mu^{T}\\textstyle\\sum^{-1}\\mu + \\textstyle\\sum_{i=1}^{N}\\mu'^{T}\\textstyle\\sum^{-1}x_{i} - \\frac{1}{2}\\mu^{T}S_{0}^{-1}\\mu + \\mu^{T}S_{0}^{-1}m_{0}$$\n",
    "\n",
    "$$\\propto -\\Bigg[\\frac{1}{2}\\mu^{T}(N\\textstyle\\sum^{-1}+S_{0}^{-1})\\mu-\\mu^{T} (\\textstyle\\sum_{i=1}^{N}\\textstyle\\sum^{-1}x_{i}+S_{0}^{-1}m_{0})\\Bigg]$$\n",
    "\n",
    "$$\\propto - \\Bigg[\\frac{1}{2}\\Bigg(\\mu-(N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}\\Bigg(\\textstyle\\sum_{i=1}^{N}x_{i}\\textstyle\\sum^{-1}+ S_{0}^{-1}m_{0}\\Bigg)\\Bigg)^{T}(N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}\\Bigg(\\textstyle\\sum_{i=1}^{N}x_{i}\\textstyle\\sum^{-1}+ S_{0}^{-1}m_{0}\\Bigg)\\Bigg)\\Bigg]$$\n",
    "\n",
    "$$rewriting\\;\\;back\\;\\;to\\;\\;the\\;\\;log\\;\\;domain:$$\n",
    "\n",
    "$$\\propto e^{- \\Big[\\frac{1}{2}\\Big(\\mu-(N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}\\Big(\\textstyle\\sum_{i=1}^{N}x_{i}\\textstyle\\sum^{-1}+ S_{0}^{-1}m_{0}\\Big)\\Big)^{T}(N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}\\Big(\\textstyle\\sum_{i=1}^{N}x_{i}\\textstyle\\sum^{-1}+ S_{0}^{-1}m_{0}\\Big)\\Big)\\Big]}$$\n",
    "\n",
    "$$\\propto \\mathcal{N}(\\mu,\\sigma)$$\n",
    "\n",
    "$$where\\;\\;\\mu:\\;\\; (N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}\\Bigg(\\textstyle\\sum_{i=1}^{N}x_{i}\\textstyle\\sum^{-1}+ S_{0}^{-1}m_{0}\\Bigg)$$\n",
    "\n",
    "$$and\\;\\;where\\;\\;\\sigma:\\;\\;(N\\textstyle\\sum^{-1}+S_{0}^{-1})^{-1}$$\n",
    "\n",
    "\n",
    "**(b)**\n",
    "\n",
    "Mean vector with maximum likelihood estimation: [0.25964287 0.29578549]\n",
    "\n",
    "Mean vector with bayesian method: [0.12982143 0.14789275]\n",
    "\n",
    "By comparing the results, it is evident that the bayesian method allows us to compute a mean vector that is clsoer to the true mean vector $\\mu = [0,0]^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00815e6f2da26a93a33186b998f6ff9f",
     "grade": false,
     "grade_id": "cell-b796d5f298b01017",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16065766  0.04224719]\n",
      "[-0.08032883  0.02112359]\n"
     ]
    }
   ],
   "source": [
    "# template for 2(b)\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "S0 = np.array([[0.1, 0],[0, 0.1]])\n",
    "Sigma = np.array([[1, 0],[0, 1]])\n",
    "N = 10\n",
    "\n",
    "# Sample N bivariate normal vectors\n",
    "# compute MLE and also the posterior mean solution\n",
    "\n",
    "# x = ? #EXERCISE\n",
    "# mle = ? #EXERCISE\n",
    "# posterior_mean = ? #EXERCISE \n",
    "\n",
    "# YOUR CODE HERE\n",
    "try: \n",
    "    mean = np.array([0,0])\n",
    "    samples = np.random.multivariate_normal(mean, Sigma, N)\n",
    "    mle = 1/N*np.sum(samples, axis=0) \n",
    "    \n",
    "    m0 = np.array([0,0]).T\n",
    "    posterior_sigma = np.linalg.inv(np.linalg.inv(S0) + N*np.linalg.inv(Sigma))\n",
    "    posterior_mean = posterior_sigma@(np.linalg.inv(S0)@m0 + N*np.linalg.inv(Sigma)@np.mean(samples,axis=0))\n",
    "except:\n",
    "    raise NotImplementedError()\n",
    "print(mle)\n",
    "print(posterior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "147ce5e8851365884434308b64b63781",
     "grade": false,
     "grade_id": "cell-7be0ef89739786a2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Problem 3: Posterior of regression weights\n",
    "\n",
    "Suppose $y_{i}=\\mathbf{w}^{T}\\mathbf{x}_{i}+\\epsilon_{i},$ for $i=1,\\ldots,n,$ where $\\epsilon_{i}\\sim \\mathcal{N}(0,\\beta^{-1})$. Assume a prior $$\\mathbf{w} \\sim \\mathcal{N} (\\mathbf{0},\\alpha^{-1}\\mathbf{I}).$$ Use 'completing the square' to show that the posterior of $\\mathbf{w}$ is given by $p(\\mathbf{w} \\mid \\mathbf{y}, \\mathbf{x}, \\alpha, \\beta)=\\mathcal{N}(\\mathbf{w} \\mid \\mathbf{m}, \\mathbf{S}),$ where \n",
    "\\begin{align*}\n",
    "    \\mathbf{S} &= \\left( \\alpha \\mathbf{I} + \\beta \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^T \\right)^{-1}\\;, \\\\\n",
    "    \\mathbf{m} &= \\beta \\mathbf{S} \\sum_{i=1}^{n} y_i \\mathbf{x}_i.\n",
    "\\end{align*}\n",
    "\n",
    "Write your solution in LateX or attach a picture of the solution in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "091354d32092b0ed4f2a8db412fe2c5c",
     "grade": true,
     "grade_id": "cell-f73f220569fc8494",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$\\frac{p(w|m)p(m)}{p(w)}$$\n",
    "\n",
    "$$rewriting\\;\\;in\\;\\;the\\;\\;log\\;\\;domain:$$\n",
    "\n",
    "$$ln\\;\\frac{p(w|m)p(m)}{p(w)}$$\n",
    "\n",
    "$$\\sum_{i=1}^{N}ln(p(w(m))+ln(p(m))-ln(w)$$\n",
    "\n",
    "$$opening\\;\\;the\\;\\;exponents:$$\n",
    "\n",
    "$$\\frac{1}{s\\pi}\\sum_{i=1}^{N}(y_{i}-f(x_{i})^{2}+\\frac{2}{\\alpha}||w||^{2}+constants$$\n",
    "\n",
    "$$\\frac{1}{s\\pi}||(y_{i}-\\beta w)||^{2}+\\frac{2}{\\alpha}||w||^{2}+constants$$\n",
    "\n",
    "$$\\frac{1}{s\\pi}(y_{i}-\\beta w)^{T}(y_{i}-\\sum_{i=1}w)+\\frac{2}{\\alpha}w^{T}w+constants$$\n",
    "\n",
    "$$\\frac{1}{2}w^{T}(\\beta^{T}\\beta/\\sigma^{2}+\\alpha\\mathbf{I})w-\\frac{1}{2}y^{T}\\beta w /\\sigma^{2}-\\frac{1}{2}y^{T}\\beta w /\\sigma^{2} + constants$$\n",
    "\n",
    "$$\\frac{1}{2}(w-\\hat{w})^{T}\\sum^{-1}(w-\\hat{w})+constants$$\n",
    "\n",
    "$$rewriting\\;\\;back\\;\\;to\\;\\;the\\;\\;log\\;\\;domain:$$\n",
    "\n",
    "$$e^{\\frac{1}{2}(w-\\hat{w})^{T}\\sum^{-1}(w-\\hat{w})+constants}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5ef24fa9a53a18fa924cb8a3e8db9b0",
     "grade": true,
     "grade_id": "cell-395759c1570192ac",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
